{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb33e69",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35adf023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_aktivitas</th>\n",
       "      <th>kategori</th>\n",
       "      <th>tingkat_aktivitas</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya keluar dari zona nyaman saya dan meningga...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Menengah</td>\n",
       "      <td>Guts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya berani mengubah hidup saya dengan berpind...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Berat</td>\n",
       "      <td>Guts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saya mengambil risiko besar dalam hidup saya k...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Ringan</td>\n",
       "      <td>Guts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saya percaya bahwa langkah besar saya akan mem...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Ringan</td>\n",
       "      <td>Guts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saya melangkah maju meskipun saya merasa takut...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Menengah</td>\n",
       "      <td>Guts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_aktivitas kategori  \\\n",
       "0  Saya keluar dari zona nyaman saya dan meningga...     Guts   \n",
       "1  Saya berani mengubah hidup saya dengan berpind...     Guts   \n",
       "2  Saya mengambil risiko besar dalam hidup saya k...     Guts   \n",
       "3  Saya percaya bahwa langkah besar saya akan mem...     Guts   \n",
       "4  Saya melangkah maju meskipun saya merasa takut...     Guts   \n",
       "\n",
       "  tingkat_aktivitas category  \n",
       "0          Menengah     Guts  \n",
       "1             Berat     Guts  \n",
       "2            Ringan     Guts  \n",
       "3            Ringan     Guts  \n",
       "4          Menengah     Guts  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all uploaded datasets\n",
    "guts_df = pd.read_csv(\"E:/Coding/persona-ai/datasets/guts_dataset.csv\")\n",
    "health_df = pd.read_csv(\"E:/Coding/persona-ai/datasets/health_dataset.csv\")\n",
    "kindness_df = pd.read_csv(\"E:/Coding/persona-ai/datasets/kindness_dataset.csv\")\n",
    "knowledge_df = pd.read_csv(\"E:/Coding/persona-ai/datasets/knowledge_dataset.csv\")\n",
    "proficiency_df = pd.read_csv(\"E:/Coding/persona-ai/datasets/proficiency_dataset.csv\")\n",
    "charm_df = pd.read_csv(\"E:/Coding/persona-ai/datasets/charm_dataset.csv\")\n",
    "\n",
    "# Tambahkan label kategori ke masing-masing dataset\n",
    "guts_df[\"category\"] = \"Guts\"\n",
    "health_df[\"category\"] = \"Health\"\n",
    "kindness_df[\"category\"] = \"Kindness\"\n",
    "knowledge_df[\"category\"] = \"Knowledge\"\n",
    "proficiency_df[\"category\"] = \"Proficiency\"\n",
    "charm_df[\"category\"] = \"Charm\"\n",
    "\n",
    "# Gabungkan semua dataset jadi satu\n",
    "all_data = pd.concat([guts_df, health_df, kindness_df, knowledge_df, proficiency_df, charm_df], ignore_index=True)\n",
    "\n",
    "# Lihat 5 data teratas\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568e515",
   "metadata": {},
   "source": [
    "## Encode Label Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f022d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "all_data[\"label\"] = label_encoder.fit_transform(all_data[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aef284",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c3ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    all_data[\"text_aktivitas\"].tolist(),\n",
    "    all_data[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=all_data[\"label\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509dce2",
   "metadata": {},
   "source": [
    "# Tokenize with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d00d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a316471",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dafe58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def convert_to_tf_dataset(encodings, labels):\n",
    "    return tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            \"input_ids\": encodings[\"input_ids\"],\n",
    "            \"attention_mask\": encodings[\"attention_mask\"]\n",
    "        },\n",
    "        labels\n",
    "    ))\n",
    "\n",
    "train_dataset = convert_to_tf_dataset(train_encodings, train_labels).shuffle(1000).batch(16)\n",
    "test_dataset = convert_to_tf_dataset(test_encodings, test_labels).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b846195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbee947",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c0ad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\Aim\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "95/95 [==============================] - 188s 2s/step - loss: 0.9664 - accuracy: 0.6638 - val_loss: 0.2384 - val_accuracy: 0.9416\n",
      "Epoch 2/5\n",
      "95/95 [==============================] - 171s 2s/step - loss: 0.1607 - accuracy: 0.9588 - val_loss: 0.0438 - val_accuracy: 0.9947\n",
      "Epoch 3/5\n",
      "95/95 [==============================] - 170s 2s/step - loss: 0.1391 - accuracy: 0.9681 - val_loss: 0.0389 - val_accuracy: 0.9920\n",
      "Epoch 4/5\n",
      "95/95 [==============================] - 171s 2s/step - loss: 0.0742 - accuracy: 0.9814 - val_loss: 0.0319 - val_accuracy: 0.9947\n",
      "Epoch 5/5\n",
      "95/95 [==============================] - 170s 2s/step - loss: 0.0284 - accuracy: 0.9947 - val_loss: 0.0171 - val_accuracy: 0.9947\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=5  # Bisa disesuaikan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74a48aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./persona_classifier\\\\tokenizer_config.json',\n",
       " './persona_classifier\\\\special_tokens_map.json',\n",
       " './persona_classifier\\\\vocab.txt',\n",
       " './persona_classifier\\\\added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./persona_classifier\")\n",
    "tokenizer.save_pretrained(\"./persona_classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
