{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1aa391",
   "metadata": {},
   "source": [
    "# Model 1: Klasifikasi Aktivitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f191c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae75aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_aktivitas</th>\n",
       "      <th>kategori</th>\n",
       "      <th>tingkat_aktivitas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>Saya berusaha untuk memberi perhatian lebih ke...</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Berat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>Saya berbicara dengan nada suara yang menyenan...</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Ringan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>Saya berusaha untuk mengerti perasaan orang la...</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Berat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>Saya berusaha untuk mengerti perasaan orang la...</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Ringan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>Saya mencoba untuk menjadi orang yang menyenan...</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Ringan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_aktivitas kategori  \\\n",
       "1877  Saya berusaha untuk memberi perhatian lebih ke...    Charm   \n",
       "1878  Saya berbicara dengan nada suara yang menyenan...    Charm   \n",
       "1879  Saya berusaha untuk mengerti perasaan orang la...    Charm   \n",
       "1880  Saya berusaha untuk mengerti perasaan orang la...    Charm   \n",
       "1881  Saya mencoba untuk menjadi orang yang menyenan...    Charm   \n",
       "\n",
       "     tingkat_aktivitas  \n",
       "1877             Berat  \n",
       "1878            Ringan  \n",
       "1879             Berat  \n",
       "1880            Ringan  \n",
       "1881            Ringan  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [\n",
    "    \"guts_dataset.csv\", \"health_dataset.csv\", \"kindness_dataset.csv\",\n",
    "    \"knowledge_dataset.csv\", \"proficiency_dataset.csv\", \"charm_dataset.csv\"\n",
    "]\n",
    "paths = [f\"E:/Coding/persona-ai/datasets/{p}\" for p in paths]\n",
    "\n",
    "df = pd.concat([pd.read_csv(p) for p in paths], ignore_index=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1cca426",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"kategori\"])\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "texts = df[\"text_aktivitas\"].tolist()\n",
    "labels = df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e377000",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a2dc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_vec, y_train)\n",
    "\n",
    "texts_resampled = [\" \".join(words) for words in vectorizer.inverse_transform(X_res)]\n",
    "labels_resampled = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad143191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize (train) with IndoBERT tokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    texts_resampled, truncation=True, padding=True, max_length=128, return_tensors=\"tf\"\n",
    ")\n",
    "train_labels_tensor = tf.convert_to_tensor(labels_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad70bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize (test)\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    X_test, truncation=True, padding=True, max_length=128, return_tensors=\"tf\"\n",
    ")\n",
    "test_labels_tensor = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with Stratified K-Fold (on train only)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_labels_tensor)), train_labels_tensor)):\n",
    "    print(f\"\\nüöÄ Fold {fold + 1}\")\n",
    "\n",
    "    train_inputs = {key: tf.gather(val, train_idx) for key, val in train_encodings.items()}\n",
    "    val_inputs = {key: tf.gather(val, val_idx) for key, val in train_encodings.items()}\n",
    "    train_labels = tf.gather(train_labels_tensor, train_idx)\n",
    "    val_labels = tf.gather(train_labels_tensor, val_idx)\n",
    "\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1', num_labels=len(label_mapping)\n",
    "    )\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "    model.fit(\n",
    "        train_inputs,\n",
    "        train_labels,\n",
    "        validation_data=(val_inputs, val_labels),\n",
    "        epochs=3,\n",
    "        batch_size=16\n",
    "    )\n",
    "\n",
    "    model.save_pretrained(f\"personaai_bert_fold{fold+1}\")\n",
    "    tokenizer.save_pretrained(f\"personaai_bert_fold{fold+1}\")\n",
    "    print(f\"‚úÖ Model untuk fold {fold + 1} disimpan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd9c41",
   "metadata": {},
   "source": [
    "## Evaluasi Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f3c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluasi model terakhir pada test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at personaai_bert_fold3 were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at personaai_bert_fold3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 6s 392ms/step - loss: 0.0525 - sparse_categorical_accuracy: 0.9894\n",
      "\n",
      "üéØ Test Accuracy: 98.94%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä Evaluasi model terakhir pada test set\")\n",
    "\n",
    "final_model = TFBertForSequenceClassification.from_pretrained(\"personaai_bert_fold3\")\n",
    "final_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "test_results = final_model.evaluate(test_encodings, test_labels_tensor)\n",
    "print(f\"\\nüéØ Test Accuracy: {test_results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7888d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 404ms/step\n",
      "\n",
      "üìÑ Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Charm       1.00      0.98      0.99        50\n",
      "        Guts       1.00      1.00      1.00        44\n",
      "      Health       0.98      1.00      0.99        60\n",
      "    Kindness       1.00      1.00      1.00        45\n",
      "   Knowledge       0.97      1.00      0.98        98\n",
      " Proficiency       1.00      0.96      0.98        80\n",
      "\n",
      "    accuracy                           0.99       377\n",
      "   macro avg       0.99      0.99      0.99       377\n",
      "weighted avg       0.99      0.99      0.99       377\n",
      "\n",
      "üìâ Confusion Matrix\n",
      "[[49  0  1  0  0  0]\n",
      " [ 0 44  0  0  0  0]\n",
      " [ 0  0 60  0  0  0]\n",
      " [ 0  0  0 45  0  0]\n",
      " [ 0  0  0  0 98  0]\n",
      " [ 0  0  0  0  3 77]]\n",
      "\n",
      "üìå Detail Metrics:\n",
      "Accuracy : 0.9894\n",
      "Precision: 0.9897\n",
      "Recall   : 0.9894\n",
      "F1-Score : 0.9894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Ambil prediksi logit dan ubah ke label prediksi\n",
    "logits = final_model.predict(test_encodings).logits\n",
    "y_pred = np.argmax(logits, axis=1)\n",
    "y_true = y_test  # Sudah dalam format list\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìÑ Classification Report\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"üìâ Confusion Matrix\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Jika ingin metrik satuan:\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nüìå Detail Metrics:\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1-Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faba17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at personaai_bert_fold1 were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at personaai_bert_fold1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**üéØ Prediksi Kategori: `HEALTH`**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**üéØ Prediksi Kategori: `PROFICIENCY`**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**üéØ Prediksi Kategori: `KINDNESS`**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**üéØ Prediksi Kategori: `CHARM`**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**üéØ Prediksi Kategori: `KINDNESS`**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Terima kasih, selesai.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# =======================\n",
    "# Load Model dan Tokenizer\n",
    "# =======================\n",
    "model_path = \"personaai_bert_fold1\"  # pastikan folder ini sudah ada dan berisi model/tokenizer hasil training\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Mapping label sesuai training-mu\n",
    "label_mapping = {\n",
    "    0: \"charm\",\n",
    "    1: \"guts\",\n",
    "    2: \"health\",\n",
    "    3: \"kindness\",\n",
    "    4: \"knowledge\",\n",
    "    5: \"proficiency\"\n",
    "}\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# =======================\n",
    "# Fungsi Prediksi\n",
    "# =======================\n",
    "def predict_category(text):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    logits = model(encoding).logits\n",
    "    pred = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    return label_mapping[pred]\n",
    "\n",
    "# =======================\n",
    "# Interaktif di Notebook\n",
    "# =======================\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def run_manual_prediction():\n",
    "    while True:\n",
    "        text = input(\"üì• Masukkan teks aktivitas (atau ketik 'exit' untuk keluar): \")\n",
    "        if text.lower() == \"exit\":\n",
    "            print(\"üëã Terima kasih, selesai.\")\n",
    "            break\n",
    "        pred = predict_category(text)\n",
    "        display(Markdown(f\"**üéØ Prediksi Kategori: `{pred.upper()}`**\\n\"))\n",
    "\n",
    "# Jalankan fungsi interaktif:\n",
    "run_manual_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de917bb5",
   "metadata": {},
   "source": [
    "# Model 2: Klasifikasi Tingkat Aktivitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6259ac2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_aktivitas</th>\n",
       "      <th>kategori</th>\n",
       "      <th>tingkat_aktivitas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saya keluar dari zona nyaman saya dan meningga...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Menengah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya berani mengubah hidup saya dengan berpind...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Berat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saya mengambil risiko besar dalam hidup saya k...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Ringan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saya percaya bahwa langkah besar saya akan mem...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Ringan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saya melangkah maju meskipun saya merasa takut...</td>\n",
       "      <td>Guts</td>\n",
       "      <td>Menengah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_aktivitas kategori  \\\n",
       "0  Saya keluar dari zona nyaman saya dan meningga...     Guts   \n",
       "1  Saya berani mengubah hidup saya dengan berpind...     Guts   \n",
       "2  Saya mengambil risiko besar dalam hidup saya k...     Guts   \n",
       "3  Saya percaya bahwa langkah besar saya akan mem...     Guts   \n",
       "4  Saya melangkah maju meskipun saya merasa takut...     Guts   \n",
       "\n",
       "  tingkat_aktivitas  \n",
       "0          Menengah  \n",
       "1             Berat  \n",
       "2            Ringan  \n",
       "3            Ringan  \n",
       "4          Menengah  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [\n",
    "    \"guts_dataset.csv\", \"health_dataset.csv\", \"kindness_dataset.csv\",\n",
    "    \"knowledge_dataset.csv\", \"proficiency_dataset.csv\", \"charm_dataset.csv\"\n",
    "]\n",
    "paths = [f\"E:/Coding/persona-ai/datasets/{p}\" for p in paths]\n",
    "df = pd.concat([pd.read_csv(p) for p in paths], ignore_index=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13f51478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_xp\"] = label_encoder.fit_transform(df[\"tingkat_aktivitas\"])\n",
    "label_mapping_xp = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "texts = df[\"text_aktivitas\"].tolist()\n",
    "labels = df[\"label_xp\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1971fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Distribusi setelah resampling: Counter({1: 934, 0: 934, 2: 934})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "df_text_label = pd.DataFrame({\"text\": texts, \"label\": labels})\n",
    "texts_resampled, labels_resampled = ros.fit_resample(df_text_label[[\"text\"]], df_text_label[\"label\"])\n",
    "texts_resampled = texts_resampled[\"text\"].tolist()\n",
    "\n",
    "print(\"‚úÖ Distribusi setelah resampling:\", Counter(labels_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6577be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "train_encodings = tokenizer(\n",
    "    texts_resampled, truncation=True, padding=True, max_length=128, return_tensors=\"tf\"\n",
    ")\n",
    "train_labels_tensor = tf.convert_to_tensor(labels_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5b23e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Fold 1\n",
      "\n",
      "üöÄ Fold 2\n",
      "\n",
      "üöÄ Fold 3\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_labels_tensor)), train_labels_tensor)):\n",
    "    print(f\"\\nüöÄ Fold {fold + 1}\")\n",
    "\n",
    "    train_inputs = {key: tf.gather(val, train_idx) for key, val in train_encodings.items()}\n",
    "    val_inputs = {key: tf.gather(val, val_idx) for key, val in train_encodings.items()}\n",
    "    train_labels = tf.gather(train_labels_tensor, train_idx)\n",
    "    val_labels = tf.gather(train_labels_tensor, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d3d421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "117/117 [==============================] - 159s 1s/step - loss: 1.1185 - sparse_categorical_accuracy: 0.3469 - val_loss: 1.0968 - val_sparse_categorical_accuracy: 0.3319\n",
      "Epoch 2/15\n",
      "117/117 [==============================] - 138s 1s/step - loss: 1.0827 - sparse_categorical_accuracy: 0.4074 - val_loss: 1.0587 - val_sparse_categorical_accuracy: 0.4486\n",
      "Epoch 3/15\n",
      "117/117 [==============================] - 138s 1s/step - loss: 0.9829 - sparse_categorical_accuracy: 0.5091 - val_loss: 1.0319 - val_sparse_categorical_accuracy: 0.4872\n",
      "Epoch 4/15\n",
      "117/117 [==============================] - 138s 1s/step - loss: 0.8516 - sparse_categorical_accuracy: 0.6146 - val_loss: 1.0003 - val_sparse_categorical_accuracy: 0.5343\n",
      "Epoch 5/15\n",
      "117/117 [==============================] - 137s 1s/step - loss: 0.6976 - sparse_categorical_accuracy: 0.7061 - val_loss: 1.0345 - val_sparse_categorical_accuracy: 0.5418\n",
      "Epoch 6/15\n",
      "117/117 [==============================] - 138s 1s/step - loss: 0.5750 - sparse_categorical_accuracy: 0.7623 - val_loss: 1.0595 - val_sparse_categorical_accuracy: 0.5621\n",
      "Epoch 7/15\n",
      "117/117 [==============================] - 137s 1s/step - loss: 0.4426 - sparse_categorical_accuracy: 0.8249 - val_loss: 1.0756 - val_sparse_categorical_accuracy: 0.6231\n",
      "Epoch 8/15\n",
      "117/117 [==============================] - 138s 1s/step - loss: 0.3338 - sparse_categorical_accuracy: 0.8721 - val_loss: 1.1699 - val_sparse_categorical_accuracy: 0.6231\n",
      "Epoch 9/15\n",
      "117/117 [==============================] - 137s 1s/step - loss: 0.2760 - sparse_categorical_accuracy: 0.8940 - val_loss: 1.2740 - val_sparse_categorical_accuracy: 0.6285\n",
      "Epoch 10/15\n",
      "117/117 [==============================] - 138s 1s/step - loss: 0.2381 - sparse_categorical_accuracy: 0.9101 - val_loss: 1.3777 - val_sparse_categorical_accuracy: 0.6424\n",
      "Epoch 11/15\n",
      "117/117 [==============================] - 138s 1s/step - loss: 0.1536 - sparse_categorical_accuracy: 0.9449 - val_loss: 1.4658 - val_sparse_categorical_accuracy: 0.6456\n",
      "Epoch 12/15\n",
      "117/117 [==============================] - 146s 1s/step - loss: 0.1550 - sparse_categorical_accuracy: 0.9449 - val_loss: 1.5468 - val_sparse_categorical_accuracy: 0.6456\n",
      "Epoch 13/15\n",
      "117/117 [==============================] - 143s 1s/step - loss: 0.1337 - sparse_categorical_accuracy: 0.9545 - val_loss: 1.3807 - val_sparse_categorical_accuracy: 0.6542\n",
      "Epoch 14/15\n",
      "117/117 [==============================] - 146s 1s/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9690 - val_loss: 1.6316 - val_sparse_categorical_accuracy: 0.6681\n",
      "Epoch 15/15\n",
      "117/117 [==============================] - 147s 1s/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9663 - val_loss: 1.5597 - val_sparse_categorical_accuracy: 0.6627\n",
      "‚úÖ Model tingkat aktivitas untuk fold 3 disimpan di personaai_xp_fold3\n"
     ]
    }
   ],
   "source": [
    "model2 = TFBertForSequenceClassification.from_pretrained(\n",
    "    'indobenchmark/indobert-base-p1', num_labels=len(label_mapping_xp)\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "model2.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "model2.fit(\n",
    "    train_inputs, train_labels,\n",
    "    validation_data=(val_inputs, val_labels),\n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "save_path = f\"personaai_xp_fold{fold+1}\"\n",
    "model2.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\"‚úÖ Model tingkat aktivitas untuk fold {fold + 1} disimpan di {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e43f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluasi model terakhir pada test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at personaai_xp_fold3 were not used when initializing TFBertForSequenceClassification: ['dropout_1025']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at personaai_xp_fold3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 401ms/step - loss: 0.6737 - sparse_categorical_accuracy: 0.8462\n",
      "\n",
      "üéØ Test Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìä Evaluasi model terakhir pada test set\")\n",
    "\n",
    "final2 = TFBertForSequenceClassification.from_pretrained(\"personaai_xp_fold3\")\n",
    "final2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "test_results = final2.evaluate(test_encodings, test_labels_tensor)\n",
    "print(f\"\\nüéØ Test Accuracy: {test_results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ea6c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating Model 2 Model\n",
      "============================================================\n",
      "12/12 [==============================] - 7s 381ms/step\n",
      "\n",
      "üìÑ Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Berat       0.80      0.96      0.88        77\n",
      "    Menengah       0.78      0.87      0.82       113\n",
      "      Ringan       0.92      0.79      0.85       187\n",
      "\n",
      "    accuracy                           0.85       377\n",
      "   macro avg       0.84      0.87      0.85       377\n",
      "weighted avg       0.85      0.85      0.85       377\n",
      "\n",
      "\n",
      "üìâ Confusion Matrix\n",
      "[[ 74   1   2]\n",
      " [  4  98  11]\n",
      " [ 14  26 147]]\n",
      "\n",
      "üìå Detail Metrics:\n",
      "Accuracy : 0.8462\n",
      "Precision: 0.8550\n",
      "Recall   : 0.8462\n",
      "F1-Score : 0.8460\n",
      "\n",
      "üìä Class Distribution Analysis\n",
      "Berat: 77 actual samples, 92 predicted samples\n",
      "Menengah: 113 actual samples, 125 predicted samples\n",
      "Ringan: 187 actual samples, 160 predicted samples\n",
      "\n",
      "üìç Per-Class Metrics:\n",
      "      Class  Precision    Recall  F1-Score\n",
      "0     Berat   0.804348  0.961039  0.875740\n",
      "1  Menengah   0.784000  0.867257  0.823529\n",
      "2    Ringan   0.918750  0.786096  0.847262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a function for model evaluation\n",
    "def evaluate_model(model, test_encodings, y_test, label_encoder, fold_name=\"Current\"):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation function that handles warnings properly\n",
    "    and provides detailed visualizations.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {fold_name} Model\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get prediction logits and convert to predicted labels\n",
    "    logits = model.predict(test_encodings).logits\n",
    "    y_pred = np.argmax(logits, axis=1)\n",
    "    y_true = y_test  # Already in list format\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nüìÑ Classification Report\")\n",
    "    class_report = classification_report(y_true, y_pred, \n",
    "                                        target_names=label_encoder.classes_,\n",
    "                                        zero_division=0)\n",
    "    print(class_report)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nüìâ Confusion Matrix\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Calculate metrics with proper handling of zero divisions\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüìå Detail Metrics:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-Score : {f1:.4f}\")\n",
    "    \n",
    "    # Additional analysis: class distribution\n",
    "    print(\"\\nüìä Class Distribution Analysis\")\n",
    "    class_count_true = np.bincount(y_true)\n",
    "    class_count_pred = np.bincount(y_pred)\n",
    "    \n",
    "    # Handle case where bincount dimensions don't match number of classes\n",
    "    if len(class_count_true) < len(label_encoder.classes_):\n",
    "        class_count_true = np.pad(class_count_true, \n",
    "                                 (0, len(label_encoder.classes_) - len(class_count_true)))\n",
    "    if len(class_count_pred) < len(label_encoder.classes_):\n",
    "        class_count_pred = np.pad(class_count_pred, \n",
    "                                 (0, len(label_encoder.classes_) - len(class_count_pred)))\n",
    "    \n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"{class_name}: {class_count_true[i]} actual samples, {class_count_pred[i]} predicted samples\")\n",
    "    \n",
    "    \n",
    "    # Find problematic classes (where no samples were predicted)\n",
    "    problematic_classes = [label_encoder.classes_[i] \n",
    "                          for i in range(len(label_encoder.classes_)) \n",
    "                          if i < len(class_count_pred) and class_count_pred[i] == 0]\n",
    "    \n",
    "    if problematic_classes:\n",
    "        print(\"\\n‚ö†Ô∏è Warning: The following classes have no predicted samples:\")\n",
    "        for cls in problematic_classes:\n",
    "            print(f\"- {cls}\")\n",
    "        print(\"This can lead to ill-defined precision for these classes.\")\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    print(\"\\nüìç Per-Class Metrics:\")\n",
    "    per_class_precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    per_class_recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    per_class_f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    \n",
    "    # Make sure metrics arrays match the number of classes\n",
    "    if len(per_class_precision) < len(label_encoder.classes_):\n",
    "        per_class_precision = np.pad(per_class_precision, \n",
    "                                   (0, len(label_encoder.classes_) - len(per_class_precision)))\n",
    "    if len(per_class_recall) < len(label_encoder.classes_):\n",
    "        per_class_recall = np.pad(per_class_recall, \n",
    "                                (0, len(label_encoder.classes_) - len(per_class_recall)))\n",
    "    if len(per_class_f1) < len(label_encoder.classes_):\n",
    "        per_class_f1 = np.pad(per_class_f1, \n",
    "                             (0, len(label_encoder.classes_) - len(per_class_f1)))\n",
    "    \n",
    "    # Create a DataFrame for per-class metrics\n",
    "    per_class_df = pd.DataFrame({\n",
    "        'Class': label_encoder.classes_,\n",
    "        'Precision': per_class_precision[:len(label_encoder.classes_)],\n",
    "        'Recall': per_class_recall[:len(label_encoder.classes_)],\n",
    "        'F1-Score': per_class_f1[:len(label_encoder.classes_)]\n",
    "    })\n",
    "    \n",
    "    print(per_class_df)\n",
    "\n",
    "# To evaluate a single model:\n",
    "results = evaluate_model(model2, test_encodings, y_test, label_encoder, \"Model 2\")\n",
    "\n",
    "# To evaluate all fold models together:\n",
    "def evaluate_all_folds(fold_models, test_encodings, y_test, label_encoder):\n",
    "    \"\"\"\n",
    "    Evaluate all fold models and compare their performance\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Evaluate each fold model\n",
    "    for i, model in enumerate(fold_models):\n",
    "        print(f\"\\nEvaluating Fold {i+1} Model\")\n",
    "        result = evaluate_model(model, test_encodings, y_test, label_encoder, f\"Fold {i+1}\")\n",
    "        result['fold'] = i+1\n",
    "        all_results.append(result)\n",
    "    \n",
    "    # Create ensemble predictions (majority voting)\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"Ensemble Model Evaluation (Majority Voting)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    # For each test sample\n",
    "    for i in range(len(y_test)):\n",
    "        # Get predictions from all folds\n",
    "        fold_votes = [all_results[j]['predictions'][i] for j in range(len(fold_models))]\n",
    "        # Take the most common prediction (majority vote)\n",
    "        from collections import Counter\n",
    "        most_common = Counter(fold_votes).most_common(1)[0][0]\n",
    "        ensemble_predictions.append(most_common)\n",
    "    \n",
    "    # Evaluate ensemble predictions\n",
    "    acc = accuracy_score(y_test, ensemble_predictions)\n",
    "    prec = precision_score(y_test, ensemble_predictions, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, ensemble_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, ensemble_predictions, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüìå Ensemble Model Metrics:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-Score : {f1:.4f}\")\n",
    "    \n",
    "    # Compare fold models\n",
    "    fold_comparison = pd.DataFrame([\n",
    "        {\n",
    "            'Fold': result['fold'],\n",
    "            'Accuracy': result['accuracy'],\n",
    "            'Precision': result['precision'],\n",
    "            'Recall': result['recall'],\n",
    "            'F1 Score': result['f1']\n",
    "        }\n",
    "        for result in all_results\n",
    "    ])\n",
    "    \n",
    "    # Add ensemble row\n",
    "    fold_comparison = pd.concat([\n",
    "        fold_comparison,\n",
    "        pd.DataFrame([{\n",
    "            'Fold': 'Ensemble',\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Score': f1\n",
    "        }])\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüìä Fold Performance Comparison:\")\n",
    "    print(fold_comparison)\n",
    "    \n",
    "    # Visualize fold comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    fold_comparison.set_index('Fold').plot(kind='bar')\n",
    "    plt.title('Performance Comparison Across Folds')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'fold_results': all_results,\n",
    "        'ensemble_accuracy': acc,\n",
    "        'ensemble_precision': prec,\n",
    "        'ensemble_recall': rec,\n",
    "        'ensemble_f1': f1,\n",
    "        'ensemble_predictions': ensemble_predictions,\n",
    "        'fold_comparison': fold_comparison\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# Define fold_models first\n",
    "# fold_models = [model1, model2, model3]  # Your three fold models\n",
    "# ensemble_results = evaluate_all_folds(fold_models, test_encodings, y_test, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a546f94",
   "metadata": {},
   "source": [
    "## Prediksi Ganda: Kategori + Tingkat Aktivitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d786eda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at personaai_bert_fold1 were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at personaai_bert_fold1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at personaai_xp_fold3 were not used when initializing TFBertForSequenceClassification: ['dropout_1025']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at personaai_xp_fold3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `HEALTH`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `PROFICIENCY`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `PROFICIENCY`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `HEALTH`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `HEALTH`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `HEALTH`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `KINDNESS`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `RINGAN`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `KNOWLEDGE`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `KNOWLEDGE`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `BERAT`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `PROFICIENCY`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**üéØ Prediksi Kategori:** `KINDNESS`\n",
       "**üìå Prediksi Tingkat Aktivitas:** `MENENGAH`\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Terima kasih, selesai.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# =======================\n",
    "# Load Model dan Tokenizer\n",
    "# =======================\n",
    "# Model 1: Prediksi Kategori\n",
    "kategori_model_path = \"personaai_bert_fold1\"\n",
    "model_kategori = TFBertForSequenceClassification.from_pretrained(kategori_model_path)\n",
    "tokenizer_kategori = BertTokenizer.from_pretrained(kategori_model_path)\n",
    "\n",
    "# Model 2: Prediksi Tingkat Aktivitas\n",
    "aktivitas_model_path = \"personaai_xp_fold3\"\n",
    "model_aktivitas = TFBertForSequenceClassification.from_pretrained(aktivitas_model_path)\n",
    "tokenizer_aktivitas = BertTokenizer.from_pretrained(aktivitas_model_path)\n",
    "\n",
    "# =======================\n",
    "# Mapping Label\n",
    "# =======================\n",
    "label_mapping_kategori = {\n",
    "    0: \"charm\",\n",
    "    1: \"guts\",\n",
    "    2: \"health\",\n",
    "    3: \"kindness\",\n",
    "    4: \"knowledge\",\n",
    "    5: \"proficiency\"\n",
    "}\n",
    "\n",
    "label_encoder_aktivitas = LabelEncoder()\n",
    "label_encoder_aktivitas.fit([\"Berat\", \"Menengah\", \"Ringan\"])\n",
    "\n",
    "# =======================\n",
    "# Fungsi Prediksi\n",
    "# =======================\n",
    "def predict_all(text):\n",
    "    # Prediksi kategori\n",
    "    enc_kat = tokenizer_kategori(text, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "    logits_kat = model_kategori(enc_kat).logits\n",
    "    pred_kat_id = tf.argmax(logits_kat, axis=1).numpy()[0]\n",
    "    pred_kat_label = label_mapping_kategori[pred_kat_id]\n",
    "\n",
    "    # Prediksi tingkat aktivitas\n",
    "    enc_akt = tokenizer_aktivitas(text, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "    logits_akt = model_aktivitas(enc_akt).logits\n",
    "    pred_akt_id = tf.argmax(logits_akt, axis=1).numpy()[0]\n",
    "    pred_akt_label = label_encoder_aktivitas.inverse_transform([pred_akt_id])[0]\n",
    "\n",
    "    return pred_kat_label, pred_akt_label\n",
    "\n",
    "# =======================\n",
    "# Fungsi Interaktif\n",
    "# =======================\n",
    "def run_double_prediction():\n",
    "    while True:\n",
    "        text = input(\"üì• Masukkan teks aktivitas (atau ketik 'exit' untuk keluar): \")\n",
    "        if text.lower() == \"exit\":\n",
    "            print(\"üëã Terima kasih, selesai.\")\n",
    "            break\n",
    "        pred_kat, pred_akt = predict_all(text)\n",
    "        display(Markdown(f\"\"\"\n",
    "**üéØ Prediksi Kategori:** `{pred_kat.upper()}`\n",
    "**üìå Prediksi Tingkat Aktivitas:** `{pred_akt.upper()}`\n",
    "        \"\"\"))\n",
    "\n",
    "# Jalankan fungsi:\n",
    "run_double_prediction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
